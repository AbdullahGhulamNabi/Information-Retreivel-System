{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 IRS - With Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have initialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already in \"files\" directory\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "# Using already created files f1.txt,f2.txt,f3.txt for IRS\n",
    "try: # using exception handling to check if we are in \"files\" directory or not\n",
    "    os.chdir(\"files\") # if not, we change our directory to \"files\"\n",
    "except: # this code block is executed if we are  in \"files\" directory\n",
    "        print(\"\"\"You are already in \"files\" directory\"\"\") \n",
    "\n",
    "totalFiles = os.listdir() # this lists total number of files in files directory\n",
    "for i in totalFiles: # iterating over the list of total number of files\n",
    "    if i != \"synonyms.txt\":\n",
    "        files_dict[i] = (file_count) # creating a dictionary with key as file names and values as 0-n indeces\n",
    "        file_count += 1 #incrementing file_count by one at each iteration\n",
    "\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in every file\n",
      " {'this', 'my', 'book', 'is', 'interesting', 'pen'} \n",
      "count of files 3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "word = list() #make a list which will include words from each file\n",
    "\n",
    "for i in files_dict: # loop through total number of files in dictionary(using keys as file names)\n",
    "    fhand = open(i,\"r\") # for each file it is opened in read mode in outer loop\n",
    "    for j in fhand: # make inner loop which will add text from each file into the \"words\" list\n",
    "        s = j.lower().split() # the words in file are converted to lower case and splitted in a list\n",
    "        word = s + word # the words are appended in the list\n",
    "        \n",
    "unique_word_set = set(word) # word list is converted to set , having unique words\n",
    "print(\"Unique words in every file\\n\",unique_word_set,\"\\ncount of files\",file_count) # print the unique set of words\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "2. Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "dictionary of unique words\n",
      " {'this': 0, 'my': 1, 'book': 2, 'is': 3, 'interesting': 4, 'pen': 5} \n",
      "\n",
      "dictionary of files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "TDM = np.zeros((file_count,len(unique_word_set))) # Term doc matrix is created using numpy array of size(filecount x length of set)\n",
    "print(TDM,\"\\n\")\n",
    "\n",
    "unique_word_dic = dict() # creating a dictionary to include unique words present in unique_word_set\n",
    "j = 0\n",
    "for i in unique_word_set: # looping in set to include these words in dictionary \n",
    "    unique_word_dic[i] = j # using j as value of dictionary\n",
    "    j += 1 # incrementing value corresponding to each key\n",
    "\n",
    "print(\"dictionary of unique words\\n\", unique_word_dic,\"\\n\")\n",
    "print(\"dictionary of files\\n\", files_dict)\n",
    "\n",
    "    \n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "2. If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "3. Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of Unique Words\n",
      " {'this': 0, 'my': 1, 'book': 2, 'is': 3, 'interesting': 4, 'pen': 5}\n",
      "\n",
      "Term Document Matrix\n",
      " [[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "contents = list() #make a list which will include words from each file\n",
    "words = str()\n",
    "\n",
    "for i in files_dict: # loop through total number of files in dictionary(using keys as file names)\n",
    "    fhand = open(i,\"r\") # for each file it is opened in read mode in outer loop\n",
    "    words = fhand.read().lower() # file is read into words string\n",
    "    words = words.split() # the string is splitted, to check if each unique word exists \n",
    "    for j in words: # inner loop checks for each splitted word\n",
    "            TDM[files_dict.get(i,0)][unique_word_dic.get(j,0)]=1 # TDM is filled where words read from file match with unique words dictionary as corresponding indeces\n",
    "\n",
    "print(\"Dictionary of Unique Words\\n\",unique_word_dic)\n",
    "print(\"\\nTerm Document Matrix\\n\",TDM)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector initially\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "col_vector = np.zeros((len(unique_word_set),1)) # making a column vector of size 6x1\n",
    "print(\"colVector initially\\n\",col_vector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: this is my ballpoint\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching:  \")\n",
    "print(\"Query is:\", query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Expected Output of query](images/Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Load Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym Dictionary\n",
      " {'write': [' compose, draft, author, create'], 'file': [' document, record, dossier, report'], 'example': [' illustration, instance, sample, demonstration'], 'query': [' question, inquiry, search, request'], 'synonym': [' equivalent, substitute, alternate, replacement'], 'retrieve': [' fetch, recover, obtain, bring back'], 'system': [' framework, structure, organization, arrangement'], 'search': [' seek, look for, explore, examine'], 'lost': [' misplaced, missing, forgotten, mislaid'], 'pen': [' write, ink, ballpoint, fountain'], 'paper': [' document, sheet, form, letter'], 'book': [' novel, volume, publication, tome'], 'read': [' peruse, scan, study, look at'], 'interesting': [' fascinating, engaging, intriguing, absorbing'], 'computer': [' machine, device, processor, laptop'], 'software': [' program, application, app, platform']}\n"
     ]
    }
   ],
   "source": [
    "lis = os.listdir() # storing all the files in a list \n",
    "for i in lis: # extracting out synonyms file from the list(loop is used in case any new file is added so we can find the file)\n",
    "    if i == \"synonyms.txt\": # where file name matches condition returns true\n",
    "        synonyms_file = i # store this file name in synonyms_file variable\n",
    "\n",
    "syn_dic = dict() # declaring a synonym dictionary\n",
    "fhand = open(synonyms_file) # reading the synonyms.txt\n",
    "\n",
    "for i in fhand: # iterating over each line of file\n",
    "    syn_split1 = i.strip().split(\":\") # spliting the values on basis of \":\", strip() function will remove the empty spaces\n",
    "    syn_key = syn_split1[0] # storing the values of string before the index 0 i.e the key value\n",
    "    syn_split2 = i.strip().split(\":\")# spliting the values on basis of \":\", strip() function will remove the empty spaces\n",
    "    syn_val = syn_split2[1:] # storing the values of string after the key value till the end of line\n",
    "    syn_dic[syn_key] = syn_val # adding key-value pair in dictionary\n",
    "print(\"Synonym Dictionary\\n\",syn_dic) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Synonym Dict Example](images\\Synonym_dict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Extend User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query\n",
      "['this', 'is', 'my', 'ballpoint', 'pen']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "expanded_query = [] # declaring a list \n",
    "# Write code to expand the query using synonyms\n",
    "#your code starts here\n",
    "expanded_query = query.strip().split(\" \") # storing the query words as a list by splitting on basis of delimiter \" \"\n",
    "for i in expanded_query: #outer loop iterates for every word in expanded query\n",
    "    for key,values in syn_dic.items(): #inner loop iterates for every key-value pair of dictionary\n",
    "        list_val = values[0] # list_Val stores the string of values\n",
    "        list_val = list_val.replace(\" \",\"\") # it remvoes all the empty spaces in list like \" pen\" -> \"pen\"(it will help in our if statement)\n",
    "        list_val = list_val.strip().split(\",\") # the string is splitted on basis of \", \" (space after comma is significant)\n",
    "        if i in list_val: # if the word in \n",
    "            expanded_query.append(key)\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"Expanded Query\")\n",
    "print(expanded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Extended Query](images\\Expanded_Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now work with extended query and find the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exists then increment the count of that word in word dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_vector after query\n",
      " [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "# for finding unique words set\n",
    "for i in expanded_query: # outer loop iterates through every word of input string\n",
    "    for j in unique_word_set: # inner loop iterates in the set of unique words\n",
    "        if i==j: # condition checks if the word in string is present in set \n",
    "            col_vector[unique_word_dic.get(i,0)] = 1 # if word is found,  at relative index of colVector it is updated\n",
    "\n",
    "print(\"col_vector after query\\n\",col_vector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      " [[3.]\n",
      " [4.]\n",
      " [2.]]\n",
      "max_index\n",
      " 1\n",
      "max\n",
      " [4.]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "result = TDM.dot(col_vector) # the dot product of term doc matrix and colVector is taken to find the resultant matrix\n",
    "print(\"result\\n\",result)\n",
    "index = result.argmax()# argmax() function is used to find the index of max value in resultant vector\n",
    "print(\"max_index\\n\",index) \n",
    "print(\"max\\n\",max(result)) # max of resultant vector is found\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name\n",
      " f2.txt\n",
      "\n",
      "Contents of file\n",
      " This is my pen\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "tuple1 = files_dict.items() # creates a tuple of key-value pair of dictionary\n",
    "for i,j in tuple1: # using two variables , one for key and one for value\n",
    "    if j==index: # if value matches our index of  max element of resultant vector\n",
    "        print(\"file name\\n\",i) # we print that key(which corresponds to the file)\n",
    "        break # if file name is found, we break the loop\n",
    "\n",
    "fhand1 = open(i) #opening the file \n",
    "cont = fhand1.read() # reading the contents of file using read() funtion\n",
    "print(\"\\nContents of file\\n\",cont)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS which can work even if query does not have exact same words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
